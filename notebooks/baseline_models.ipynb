{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc02ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df <class 'pandas.core.frame.DataFrame'> 342665\n",
      "val_df <class 'pandas.core.frame.DataFrame'> 47464\n",
      "test_df <class 'pandas.core.frame.DataFrame'> 123739\n",
      "train_matrix <class 'scipy.sparse._csr.csr_matrix'>\n",
      "val_matrix <class 'scipy.sparse._csr.csr_matrix'>\n",
      "test_matrix <class 'scipy.sparse._csr.csr_matrix'>\n",
      "user_to_idx <class 'dict'> 98975\n",
      "idx_to_user <class 'dict'> 98975\n",
      "business_to_idx <class 'dict'> 28274\n",
      "idx_to_business <class 'dict'> 28274\n",
      "business_stats <class 'pandas.core.frame.DataFrame'> 28223\n",
      "n_users <class 'int'>\n",
      "n_businesses <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('preprocessed_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "for k, v in data.items():\n",
    "    try:\n",
    "        print(k, type(v), len(v))\n",
    "    except:\n",
    "        print(k, type(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98098de5",
   "metadata": {},
   "source": [
    "## Baseline 1: Matrix Factorization (MF) Baseline\n",
    "Matrix Factorization (MF) is a classical baseline for recommendation tasks, especially when explicit ratings are available. Unlike Jaccard (a pure similarity baseline), MF is designed to predict the user’s rating for an item, and can also be used for Top-K ranking by sorting predicted scores.\n",
    "\n",
    "This MF baseline includes:\n",
    "\n",
    "1.A complete MF model definition (TensorFlow)\n",
    "\n",
    "2.Training loop\n",
    "\n",
    "3.Rating prediction, and transfered to similarity\n",
    "\n",
    "4.MSE calculation\n",
    "\n",
    "5.Top-K recommendation\n",
    "\n",
    "6.Ranking metrics (Recall@K, NDCG@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a44b5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'user_id', 'rating', 'review_text', 'pics', 'user_idx',\n",
      "       'business_idx'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>pics</th>\n",
       "      <th>user_idx</th>\n",
       "      <th>business_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6040598a65e4ba0588bb0fca</td>\n",
       "      <td>100000107216850094011</td>\n",
       "      <td>5</td>\n",
       "      <td>The food here is amazing! The curries are rich...</td>\n",
       "      <td>[{'id': 'AF1QipNCVZIuBLkTOzpgwNZz9BFCX0CD3jjNa...</td>\n",
       "      <td>98969</td>\n",
       "      <td>28121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>604056bbc6fcf1fddba0a0e0</td>\n",
       "      <td>100000107216850094011</td>\n",
       "      <td>3</td>\n",
       "      <td>Great brunch spot with bottomless coffee from ...</td>\n",
       "      <td>[{'id': 'AF1QipPC7hM3F612LEXzVAeIp-UMFtg1fIXWj...</td>\n",
       "      <td>98969</td>\n",
       "      <td>28142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6040594f65e4ba0588bb0fa1</td>\n",
       "      <td>100000107216850094011</td>\n",
       "      <td>5</td>\n",
       "      <td>Philadelphia has many excellent restaurants bu...</td>\n",
       "      <td>[{'id': 'AF1QipN0gtINkHKgJaqG-AWsN_0-od2XhMPJu...</td>\n",
       "      <td>98969</td>\n",
       "      <td>28122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6042481f2e57ebdea29c95aa</td>\n",
       "      <td>100000149611993816967</td>\n",
       "      <td>5</td>\n",
       "      <td>Great flavor, fun to share tapas and sushi. Th...</td>\n",
       "      <td>[{'id': 'AF1QipPc19S3uC5eywfMAEs7adk3RD7aaaHLd...</td>\n",
       "      <td>98785</td>\n",
       "      <td>25640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6042483cb9a6829e686e8cdd</td>\n",
       "      <td>100000149611993816967</td>\n",
       "      <td>4</td>\n",
       "      <td>Good burger great fries and onion rings</td>\n",
       "      <td>[{'id': 'AF1QipOVdGguJCQddhusocI6-crhk78AeS5ml...</td>\n",
       "      <td>98785</td>\n",
       "      <td>25639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id                user_id  rating  \\\n",
       "0  6040598a65e4ba0588bb0fca  100000107216850094011       5   \n",
       "1  604056bbc6fcf1fddba0a0e0  100000107216850094011       3   \n",
       "2  6040594f65e4ba0588bb0fa1  100000107216850094011       5   \n",
       "3  6042481f2e57ebdea29c95aa  100000149611993816967       5   \n",
       "4  6042483cb9a6829e686e8cdd  100000149611993816967       4   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  The food here is amazing! The curries are rich...   \n",
       "1  Great brunch spot with bottomless coffee from ...   \n",
       "2  Philadelphia has many excellent restaurants bu...   \n",
       "3  Great flavor, fun to share tapas and sushi. Th...   \n",
       "4            Good burger great fries and onion rings   \n",
       "\n",
       "                                                pics  user_idx  business_idx  \n",
       "0  [{'id': 'AF1QipNCVZIuBLkTOzpgwNZz9BFCX0CD3jjNa...     98969         28121  \n",
       "1  [{'id': 'AF1QipPC7hM3F612LEXzVAeIp-UMFtg1fIXWj...     98969         28142  \n",
       "2  [{'id': 'AF1QipN0gtINkHKgJaqG-AWsN_0-od2XhMPJu...     98969         28122  \n",
       "3  [{'id': 'AF1QipPc19S3uC5eywfMAEs7adk3RD7aaaHLd...     98785         25640  \n",
       "4  [{'id': 'AF1QipOVdGguJCQddhusocI6-crhk78AeS5ml...     98785         25639  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train_data.csv\")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b6ffe",
   "metadata": {},
   "source": [
    "### Part 0 — Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09e892bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98975 28274\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"preprocessed_data.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "train_df = data[\"train_df\"]\n",
    "val_df = data[\"val_df\"]\n",
    "test_df = data[\"test_df\"]\n",
    "\n",
    "user_to_idx = data[\"user_to_idx\"]\n",
    "business_to_idx = data[\"business_to_idx\"]\n",
    "\n",
    "n_users = data[\"n_users\"]\n",
    "n_businesses = data[\"n_businesses\"]\n",
    "\n",
    "print(n_users, n_businesses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ed671",
   "metadata": {},
   "source": [
    "### Part 1 — Matrix Factorization Model (TensorFlow, Keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0805d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class MF(tf.keras.Model):\n",
    "    def __init__(self, n_users, n_items, K=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_emb = tf.keras.layers.Embedding(n_users, K)\n",
    "        self.item_emb = tf.keras.layers.Embedding(n_items, K)\n",
    "        self.user_bias = tf.keras.layers.Embedding(n_users, 1)\n",
    "        self.item_bias = tf.keras.layers.Embedding(n_items, 1)\n",
    "\n",
    "        self.global_bias = tf.Variable(0.0)\n",
    "\n",
    "    def call(self, user_idx, item_idx):\n",
    "        u = self.user_emb(user_idx)\n",
    "        i = self.item_emb(item_idx)\n",
    "        bu = self.user_bias(user_idx)\n",
    "        bi = self.item_bias(item_idx)\n",
    "\n",
    "        dot = tf.reduce_sum(u * i, axis=1)\n",
    "        pred = self.global_bias + tf.squeeze(bu) + tf.squeeze(bi) + dot\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0989101c",
   "metadata": {},
   "source": [
    "### Part 2 — Training the MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a14ea1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=0.2967\n",
      "Epoch 2, loss=0.2803\n",
      "Epoch 3, loss=0.2758\n",
      "Epoch 4, loss=0.2744\n",
      "Epoch 5, loss=0.2745\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 1e-6  # small regularization strength\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.permutation(len(train_df))\n",
    "\n",
    "    for start in range(0, len(train_df), batch_size):\n",
    "        end = start + batch_size\n",
    "        batch = idx[start:end]\n",
    "\n",
    "        u = tf.gather(user_tensor, batch)\n",
    "        i = tf.gather(item_tensor, batch)\n",
    "        r = tf.gather(rating_tensor, batch)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pred = model_mf(u, i)\n",
    "\n",
    "            # MSE loss\n",
    "            mse_loss = tf.reduce_mean((pred - r) ** 2)\n",
    "\n",
    "            # L2 Regularization (IMPORTANT)\n",
    "            reg_loss = (\n",
    "                reg_lambda * tf.nn.l2_loss(model_mf.user_emb.weights[0]) +\n",
    "                reg_lambda * tf.nn.l2_loss(model_mf.item_emb.weights[0]) +\n",
    "                reg_lambda * tf.nn.l2_loss(model_mf.user_bias.weights[0]) +\n",
    "                reg_lambda * tf.nn.l2_loss(model_mf.item_bias.weights[0])\n",
    "            )\n",
    "\n",
    "            # total MF loss\n",
    "            loss = mse_loss + reg_loss\n",
    "\n",
    "        grads = tape.gradient(loss, model_mf.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model_mf.trainable_variables))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, loss={loss.numpy():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc86b33",
   "metadata": {},
   "source": [
    "### Part 3: MF is converted into similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a03f3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "mf_item_emb = model_mf.item_emb.weights[0].numpy()\n",
    "item_sim_mf = cosine_similarity(mf_item_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "587f9667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_mf_to_user(user_idx, topk=10):\n",
    "    item_ids = np.arange(n_businesses)\n",
    "\n",
    "    # Predict rating for all items for this user\n",
    "    u = tf.constant([user_idx] * n_businesses, dtype=tf.int32)\n",
    "    i = tf.constant(item_ids, dtype=tf.int32)\n",
    "    preds = model_mf(u, i).numpy()\n",
    "\n",
    "    # Remove seen items\n",
    "    seen = set(train_df[train_df.user_idx == user_idx].business_idx)\n",
    "    preds_filtered = [(biz, score) for biz, score in zip(item_ids, preds) if biz not in seen]\n",
    "\n",
    "    # Sort by predicted score\n",
    "    preds_sorted = sorted(preds_filtered, key=lambda x: x[1], reverse=True)\n",
    "    return preds_sorted[:topk]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ff792",
   "metadata": {},
   "source": [
    "### Part 4 — Recall@K and NDCG@K (General Ranking Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54490ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def recall_at_k(recommended, ground_truth, K):\n",
    "    \"\"\"\n",
    "    recommended: list of item indices predicted by the model\n",
    "    ground_truth: list of ground-truth liked items (rating >= 4)\n",
    "    \"\"\"\n",
    "    if len(ground_truth) == 0:\n",
    "        return None\n",
    "    hit = len(set(recommended[:K]) & set(ground_truth))\n",
    "    return hit / len(ground_truth)\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, K):\n",
    "    \"\"\"\n",
    "    Standard NDCG@K for ranking evaluation.\n",
    "    \"\"\"\n",
    "    dcg = 0.0\n",
    "    for rank, item in enumerate(recommended[:K], start=1):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1 / math.log2(rank + 1)\n",
    "\n",
    "    max_rel = min(K, len(ground_truth))\n",
    "    idcg = sum(1 / math.log2(rank + 1) for rank in range(1, max_rel + 1))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a96903",
   "metadata": {},
   "source": [
    "### Part 5 — Global Evaluation for MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27d6451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_mf(K=10, sample_users=2000):\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "\n",
    "    # Randomly sample users from test set\n",
    "    users = test_df.user_idx.unique()\n",
    "    users = np.random.choice(users, size=min(len(users), sample_users), replace=False)\n",
    "\n",
    "    for u in users:\n",
    "        # Use MF to recommend top-K items for this user\n",
    "        recs = [item for item, score in recommend_mf_to_user(u, topk=K)]\n",
    "\n",
    "        # Ground truth = items rated >= 4 by this user in test set\n",
    "        truth = list(test_df[(test_df.user_idx == u) & (test_df.rating >= 4)].business_idx)\n",
    "\n",
    "        # Compute metrics\n",
    "        r = recall_at_k(recs, truth, K)\n",
    "        n = ndcg_at_k(recs, truth, K)\n",
    "\n",
    "        if r is not None:\n",
    "            recalls.append(r)\n",
    "        if n is not None:\n",
    "            ndcgs.append(n)\n",
    "\n",
    "    # Return average scores\n",
    "    return np.mean(recalls), np.mean(ndcgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa917429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF Recall@10 = 0.00973370064279155\n",
      "MF NDCG@10 = 0.006545760831757247\n"
     ]
    }
   ],
   "source": [
    "recall10, ndcg10 = evaluate_mf(K=10)\n",
    "print(\"MF Recall@10 =\", recall10)\n",
    "print(\"MF NDCG@10 =\", ndcg10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251181ca",
   "metadata": {},
   "source": [
    "## Baseline 2：Item–Item Jaccard Similarity\n",
    "This is a fully functional Item–Item Jaccard Similarity baseline implementation, including:\n",
    "\n",
    "1.Building item–user mappings\n",
    "\n",
    "2.Computing item–item Jaccard similarity\n",
    "\n",
    "3.Generating Top-K recommendations for users\n",
    "\n",
    "4.Computing MSE (not theoretically meaningful, but included if required)\n",
    "\n",
    "5.Computing Recall@K and NDCG@K (the correct metrics for ranking models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44322f",
   "metadata": {},
   "source": [
    "### Part 0 — Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4603774",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data[\"train_df\"]\n",
    "test_df = data[\"test_df\"]\n",
    "\n",
    "# Ensure we only keep necessary fields\n",
    "train_df = train_df[[\"user_idx\", \"business_idx\", \"rating\"]]\n",
    "test_df = test_df[[\"user_idx\", \"business_idx\", \"rating\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c3997",
   "metadata": {},
   "source": [
    "### Part 1 — Build the Item–User Mapping (Required for Jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96f2d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "users_per_item = defaultdict(set)\n",
    "items_per_user = defaultdict(set)\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    u = row.user_idx\n",
    "    i = row.business_idx\n",
    "    users_per_item[i].add(u)\n",
    "    items_per_user[u].add(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1269a1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 28223\n",
      "Users who visited item 25639: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of items:\", len(users_per_item))\n",
    "print(\"Users who visited item 25639:\", len(users_per_item[25639]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4855b9c",
   "metadata": {},
   "source": [
    "### Part 2 — Jaccard Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdfdacf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(i, j):\n",
    "    users_i = users_per_item[i]\n",
    "    users_j = users_per_item[j]\n",
    "    \n",
    "    if len(users_i) == 0 or len(users_j) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    inter = len(users_i & users_j)\n",
    "    union = len(users_i | users_j)\n",
    "    return inter / union\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344acdb9",
   "metadata": {},
   "source": [
    "### Part 3 — Generate Top-K Recommendations (Item-Based Collaborative Filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd693d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jaccard_to_user(user_idx, topK=10):\n",
    "    seen_items = items_per_user[user_idx]\n",
    "    if len(seen_items) == 0:\n",
    "        return []\n",
    "\n",
    "    scores = defaultdict(float)\n",
    "    candidate_items = set()\n",
    "\n",
    "    # Step 1: gather candidates = only items visited by users who visited seen items\n",
    "    for item in seen_items:\n",
    "        for u in users_per_item[item]:\n",
    "            for other_item in items_per_user[u]:\n",
    "                if other_item != item:\n",
    "                    candidate_items.add(other_item)\n",
    "\n",
    "    # Step 2: compute similarity only for candidates\n",
    "    for item in seen_items:\n",
    "        for other_item in candidate_items:\n",
    "            if other_item == item:\n",
    "                continue\n",
    "            sim = jaccard_similarity(item, other_item)\n",
    "            scores[other_item] += sim\n",
    "\n",
    "    # Step 3: remove already-visited items\n",
    "    for s in seen_items:\n",
    "        scores.pop(s, None)\n",
    "\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [item for item, score in ranked[:topK]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fdf5ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22409, 4027, 5656, 13959, 14481, 2120, 24244, 25646, 21751, 13593]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_jaccard_to_user(98785, topK=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5136b72",
   "metadata": {},
   "source": [
    "### Part 4 — Recall@K and NDCG@K (Correct Metrics for Ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75782ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended, ground_truth, K):\n",
    "    if len(ground_truth) == 0:\n",
    "        return None\n",
    "    recommended_k = recommended[:K]\n",
    "    hit = len(set(recommended_k) & set(ground_truth))\n",
    "    return hit / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7b215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def ndcg_at_k(recommended, ground_truth, K):\n",
    "    dcg = 0.0\n",
    "    for rank, item in enumerate(recommended[:K], start=1):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1 / math.log2(rank + 1)\n",
    "\n",
    "    # IDCG: ideal ranking\n",
    "    max_rel = min(K, len(ground_truth))\n",
    "    idcg = sum(1 / math.log2(rank + 1) for rank in range(1, max_rel + 1))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34bcc13",
   "metadata": {},
   "source": [
    "### Part 5 — Global Evaluation for the Jaccard Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9cc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_jaccard(K=10, sample_users=2000):\n",
    "    recalls, ndcgs = [], []\n",
    "\n",
    "    users = test_df.user_idx.unique()\n",
    "    users = np.random.choice(users, size=min(len(users), sample_users), replace=False)\n",
    "\n",
    "    for u in users:\n",
    "        recs = recommend_jaccard_to_user(u, topK=K)\n",
    "\n",
    "        # ground truth = items user liked (rating >=4)\n",
    "        truth = list(test_df[(test_df.user_idx == u) & (test_df.rating >= 4)].business_idx)\n",
    "\n",
    "        r = recall_at_k(recs, truth, K)\n",
    "        n = ndcg_at_k(recs, truth, K)\n",
    "\n",
    "        if r is not None:\n",
    "            recalls.append(r)\n",
    "        if n is not None:\n",
    "            ndcgs.append(n)\n",
    "\n",
    "    return np.mean(recalls), np.mean(ndcgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4366ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Recall@10 = 0.0347732181425486\n",
      "Jaccard NDCG@10 = 0.023778397706640864\n"
     ]
    }
   ],
   "source": [
    "recall10, ndcg10 = evaluate_jaccard(K=10)\n",
    "print(\"Jaccard Recall@10 =\", recall10)\n",
    "print(\"Jaccard NDCG@10 =\", ndcg10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c876279",
   "metadata": {},
   "source": [
    "## Baseline 3: Popularity-Based Baseline（Most Popular Restaurants）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3e891",
   "metadata": {},
   "source": [
    "### Part 0 — Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a07d5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data = pickle.load(open(\"preprocessed_data.pkl\", \"rb\"))\n",
    "\n",
    "train_df = data[\"train_df\"]\n",
    "test_df  = data[\"test_df\"]\n",
    "\n",
    "# Keep necessary fields only\n",
    "train_df = train_df[[\"user_idx\", \"business_idx\", \"rating\"]]\n",
    "test_df  = test_df[[\"user_idx\", \"business_idx\", \"rating\"]]\n",
    "\n",
    "# Load business stats (optional but recommended)\n",
    "business_stats = data[\"business_stats\"]  # contains n_reviews & avg_rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7d8be",
   "metadata": {},
   "source": [
    "### Part 1 — Compute Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdade1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_df = (\n",
    "    train_df.groupby(\"business_idx\")\n",
    "            .size()\n",
    "            .reset_index(name=\"popularity\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8946a",
   "metadata": {},
   "source": [
    "### Part 2 —  popularity list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7837d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort restaurants by popularity (descending)\n",
    "popular_items = (\n",
    "    popularity_df.sort_values(\"popularity\", ascending=False)\n",
    "                 .business_idx\n",
    "                 .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1bb06",
   "metadata": {},
   "source": [
    "### Part 3 — Popularity-Based recommendation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91197169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_popularity_to_user(user_idx, topK=10):\n",
    "    seen = set(train_df[train_df.user_idx == user_idx].business_idx)\n",
    "\n",
    "    recs = []\n",
    "    for item in popular_items:\n",
    "        if item not in seen:\n",
    "            recs.append(item)\n",
    "        if len(recs) >= topK:\n",
    "            break\n",
    "    return recs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99925ee",
   "metadata": {},
   "source": [
    "### Part 4 — Recall@K / NDCG@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6104c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended, ground_truth, K):\n",
    "    if len(ground_truth) == 0:\n",
    "        return None\n",
    "    hit = len(set(recommended[:K]) & set(ground_truth))\n",
    "    return hit / len(ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b74d60ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(recommended, ground_truth, K):\n",
    "    dcg = 0.0\n",
    "    for rank, item in enumerate(recommended[:K], start=1):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1 / math.log2(rank + 1)\n",
    "\n",
    "    max_rel = min(K, len(ground_truth))\n",
    "    idcg = sum(1 / math.log2(rank + 1) for rank in range(1, max_rel + 1))\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59fc6c",
   "metadata": {},
   "source": [
    "### Part 5 — global evaluate_popularity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c865780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_popularity(K=10, sample_users=2000):\n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "\n",
    "    users = test_df.user_idx.unique()\n",
    "    users = np.random.choice(users, size=min(len(users), sample_users), replace=False)\n",
    "\n",
    "    for u in users:\n",
    "        recs = recommend_popularity_to_user(u, topK=K)\n",
    "        truth = list(test_df[(test_df.user_idx == u) & (test_df.rating >= 4)].business_idx)\n",
    "\n",
    "        r = recall_at_k(recs, truth, K)\n",
    "        n = ndcg_at_k(recs, truth, K)\n",
    "\n",
    "        if r is not None:\n",
    "            recalls.append(r)\n",
    "        if n is not None:\n",
    "            ndcgs.append(n)\n",
    "\n",
    "    return np.mean(recalls), np.mean(ndcgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4174f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity Recall@10 = 0.010103768432550519\n",
      "Popularity NDCG@10 = 0.005506666006273678\n"
     ]
    }
   ],
   "source": [
    "recall10, ndcg10 = evaluate_popularity(K=10)\n",
    "print(\"Popularity Recall@10 =\", recall10)\n",
    "print(\"Popularity NDCG@10 =\", ndcg10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9619bc",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e47cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4166c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "               BASELINE MODEL COMPARISON SUMMARY\n",
      "============================================================\n",
      "\n",
      "We compare three baseline models on the Google Local Restaurants\n",
      "recommendation task:\n",
      "\n",
      "1. Popularity-Based Recommendation\n",
      "2. Item–Item Jaccard Similarity\n",
      "3. Matrix Factorization (MF)\n",
      "\n",
      "Evaluation metrics:\n",
      "- Recall@10\n",
      "- NDCG@10\n",
      "\n",
      "===================== Quantitative Results ====================\n",
      "\n",
      "Popularity:\n",
      "    Recall@10 = 0.0101\n",
      "    NDCG@10   = 0.0055\n",
      "\n",
      "Jaccard Item–Item Similarity:\n",
      "    Recall@10 = 0.0347\n",
      "    NDCG@10   = 0.0238\n",
      "\n",
      "Matrix Factorization (MF):\n",
      "    Recall@10 = 0.0097\n",
      "    NDCG@10   = 0.0065\n",
      "\n",
      "=========================== Analysis ============================\n",
      "\n",
      "• Jaccard Similarity is the strongest baseline.\n",
      "  - Recall@10 is over 3× higher than Popularity.\n",
      "  - Recall@10 is over 3.5× higher than MF.\n",
      "  - NDCG@10 is also over 3–4× higher than the other baselines.\n",
      "  Jaccard effectively captures co-liked restaurant patterns even under sparsity.\n",
      "\n",
      "• MF underperforms due to:\n",
      "  - Extremely sparse dataset (avg ~3.46 ratings/user)\n",
      "  - Rating distribution heavily skewed toward 4–5\n",
      "  - Only 5 training epochs → underfitting\n",
      "  - MF optimizes MSE, not ranking loss\n",
      "\n",
      "• Popularity is a weak but meaningful non-personalized baseline.\n",
      "  Recommended items are identical across all users, limiting performance.\n",
      "\n",
      "========================== Conclusion ===========================\n",
      "\n",
      "Item–Item Jaccard Similarity is the best-performing baseline for\n",
      "Top-K restaurant recommendation on this dataset. It provides a\n",
      "strong personalized baseline for evaluating more advanced models\n",
      "such as improved MF, neural collaborative filtering, or\n",
      "embedding-based recommendation methods.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = f\"\"\"\n",
    "============================================================\n",
    "               BASELINE MODEL COMPARISON SUMMARY\n",
    "============================================================\n",
    "\n",
    "We compare three baseline models on the Google Local Restaurants\n",
    "recommendation task:\n",
    "\n",
    "1. Popularity-Based Recommendation\n",
    "2. Item–Item Jaccard Similarity\n",
    "3. Matrix Factorization (MF)\n",
    "\n",
    "Evaluation metrics:\n",
    "- Recall@10\n",
    "- NDCG@10\n",
    "\n",
    "===================== Quantitative Results ====================\n",
    "\n",
    "Popularity:\n",
    "    Recall@10 = 0.0101\n",
    "    NDCG@10   = 0.0055\n",
    "\n",
    "Jaccard Item–Item Similarity:\n",
    "    Recall@10 = 0.0347\n",
    "    NDCG@10   = 0.0238\n",
    "\n",
    "Matrix Factorization (MF):\n",
    "    Recall@10 = 0.0097\n",
    "    NDCG@10   = 0.0065\n",
    "\n",
    "=========================== Analysis ============================\n",
    "\n",
    "• Jaccard Similarity is the strongest baseline.\n",
    "  - Recall@10 is over 3× higher than Popularity.\n",
    "  - Recall@10 is over 3.5× higher than MF.\n",
    "  - NDCG@10 is also over 3–4× higher than the other baselines.\n",
    "  Jaccard effectively captures co-liked restaurant patterns even under sparsity.\n",
    "\n",
    "• MF underperforms due to:\n",
    "  - Extremely sparse dataset (avg ~3.46 ratings/user)\n",
    "  - Rating distribution heavily skewed toward 4–5\n",
    "  - Only 5 training epochs → underfitting\n",
    "  - MF optimizes MSE, not ranking loss\n",
    "\n",
    "• Popularity is a weak but meaningful non-personalized baseline.\n",
    "  Recommended items are identical across all users, limiting performance.\n",
    "\n",
    "========================== Conclusion ===========================\n",
    "\n",
    "Item–Item Jaccard Similarity is the best-performing baseline for\n",
    "Top-K restaurant recommendation on this dataset. It provides a\n",
    "strong personalized baseline for evaluating more advanced models\n",
    "such as improved MF, neural collaborative filtering, or\n",
    "embedding-based recommendation methods.\n",
    "\n",
    "============================================================\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88918d27",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "### Jaccard Similarity is the strongest baseline.\n",
    "\n",
    "It achieves the best performance on both metrics, outperforming popularity by more than 3× and MF by more than 3.5×.\n",
    "This demonstrates that item–item collaborative filtering based on co-liked restaurants captures useful similarity signals, even in a sparse dataset.\n",
    "\n",
    "### MF performs worse than expected.\n",
    "\n",
    "Although MF is a powerful model for explicit-feedback recommendation, its performance is limited in this dataset due to:\n",
    "\n",
    "Severe sparsity (average only 3.46 ratings per user)\n",
    "\n",
    "Highly skewed rating distribution (most ratings are 4–5)\n",
    "\n",
    "Insufficient training epochs\n",
    "\n",
    "MF optimizing MSE instead of ranking loss\n",
    "\n",
    "As a result, MF embeddings are under-trained and less effective for top-K ranking compared to Jaccard.\n",
    "\n",
    "Popularity is a weak but meaningful non-personalized baseline.\n",
    "\n",
    "Because recommendations are identical for all users, this baseline struggles to match the personalized approaches.\n",
    "However, it provides an important lower bound for model performance.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Among the three baselines, Item–Item Jaccard Similarity is clearly the best performing model for top-K restaurant recommendation on this dataset.\n",
    "It serves as a strong personalized baseline and a meaningful reference point for more advanced models such as improved MF, neural collaborative filtering, or embedding-based methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
