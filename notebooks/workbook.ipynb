{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f834195",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change this to your file ID\n",
    "FILE_ID = \"YOUR_FILE_ID\"\n",
    "URL = f\"https://cseweb.ucsd.edu/~jmcauley/datasets.html#google_restaurants\"\n",
    "OUT = \"filter_all_t.json\"\n",
    "\n",
    "if not os.path.exists(OUT):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !wget --no-check-certificate \"$URL\" -O \"$OUT\"\n",
    "else:\n",
    "    print(f\"{OUT} already exists, skip downloading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e550ae4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dd8a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(OUT, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(data, max_level=2)\n",
    "print(\"Data loaded:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f9e1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df[\"review_text\"] = df[\"review_text\"].astype(str)\n",
    "\n",
    "# Basic text cleaning\n",
    "def clean_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "df[\"clean_text\"] = df[\"review_text\"].apply(clean_text)\n",
    "\n",
    "# Create binary label: good review if rating >= 4\n",
    "df[\"label_good\"] = (df[\"rating\"] >= 4).astype(int)\n",
    "\n",
    "# Add simple features\n",
    "df[\"text_len\"] = df[\"clean_text\"].apply(len)\n",
    "df[\"word_count\"] = df[\"clean_text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "df[[\"rating\", \"label_good\", \"text_len\", \"word_count\"]].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477f33d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=df[\"rating\"])\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[\"text_len\"], bins=50, kde=True)\n",
    "plt.title(\"Text Length Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df[\"word_count\"], bins=50, kde=True)\n",
    "plt.title(\"Word Count Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307ec90",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"clean_text\"])\n",
    "y = df[\"label_good\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940b6f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=300)\n",
    "log_reg.fit(X_train, y_train)\n",
    "pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Performance ===\")\n",
    "print(classification_report(y_test, pred_lr))\n",
    "\n",
    "acc_lr = accuracy_score(y_test, pred_lr)\n",
    "f1_lr = f1_score(y_test, pred_lr)\n",
    "print(f\"Accuracy: {acc_lr:.4f}, F1: {f1_lr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336bd918",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Random Forest Performance ===\")\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "acc_rf = accuracy_score(y_test, pred_rf)\n",
    "f1_rf = f1_score(y_test, pred_rf)\n",
    "print(f\"Accuracy: {acc_rf:.4f}, F1: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78dc333",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\"],\n",
    "    \"Accuracy\": [acc_lr, acc_rf],\n",
    "    \"F1 Score\": [f1_lr, f1_rf],\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6149d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion(cm, title):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(confusion_matrix(y_test, pred_lr), \"LR Confusion Matrix\")\n",
    "plot_confusion(confusion_matrix(y_test, pred_rf), \"RF Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226d081",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = log_reg.coef_[0]\n",
    "\n",
    "top_pos_idx = np.argsort(coefs)[-15:][::-1]\n",
    "top_neg_idx = np.argsort(coefs)[:15]\n",
    "\n",
    "print(\"\\nTop positive tokens:\")\n",
    "for i in top_pos_idx:\n",
    "    print(f\"{feature_names[i]:20s}  {coefs[i]:.4f}\")\n",
    "\n",
    "print(\"\\nTop negative tokens:\")\n",
    "for i in top_neg_idx:\n",
    "    print(f\"{feature_names[i]:20s}  {coefs[i]:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
