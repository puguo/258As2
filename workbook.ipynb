{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f834195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_all_t.json already exists, skip downloading.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change this to your file ID\n",
    "FILE_ID = \"YOUR_FILE_ID\"\n",
    "URL = f\"https://mcauleylab.ucsd.edu/public_datasets/gdrive/googlelocal_restaurants/filter_all_t.json\"\n",
    "OUT = \"filter_all_t.json\"\n",
    "\n",
    "if not os.path.exists(OUT):\n",
    "    print(\"Downloading dataset...\")\n",
    "    !wget --no-check-certificate \"$URL\" -O \"$OUT\"\n",
    "else:\n",
    "    print(f\"{OUT} already exists, skip downloading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e550ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36dd8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>pics</th>\n",
       "      <th>history_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60567465d335d0abfb415b26</td>\n",
       "      <td>101074926318992653684</td>\n",
       "      <td>4</td>\n",
       "      <td>The tang of the tomato sauce is outstanding. A...</td>\n",
       "      <td>[AF1QipM-2IRmvitARbcJr7deWfe5hyVBg_ArPMQSYvq0,...</td>\n",
       "      <td>[[101074926318992653684_6056272797d555cc6fb0d1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6050fa9f5b4ccec8d5cae994</td>\n",
       "      <td>117065749986299237881</td>\n",
       "      <td>5</td>\n",
       "      <td>Chicken and waffles were really good!</td>\n",
       "      <td>[AF1QipMpfxIZUT_aymQ3qPGO-QgGYzxbtLZGmHufAp2s]</td>\n",
       "      <td>[[117065749986299237881_605206f8d8c08f462b93e8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604be10877e81aaed3cc9a1e</td>\n",
       "      <td>106700937793048450809</td>\n",
       "      <td>4</td>\n",
       "      <td>The appetizer of colossal shrimp was very good...</td>\n",
       "      <td>[AF1QipMNnqM5X9sSyZ9pXRZ1jvrURHN9bZhGdzuEXoP8,...</td>\n",
       "      <td>[[106700937793048450809_6044300b27f39b7b5d1dbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60411e017cd8bf130362365a</td>\n",
       "      <td>101643045857250355161</td>\n",
       "      <td>5</td>\n",
       "      <td>The fish tacos here  omg! The salad was great ...</td>\n",
       "      <td>[AF1QipM-a6AGGp4Hgk5RD0gY5sDRp5kEfB1hZLvlRkft,...</td>\n",
       "      <td>[[101643045857250355161_604fbdd099686c10168c91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>604139dd7cd8bf1303624208</td>\n",
       "      <td>109802745326785766951</td>\n",
       "      <td>4</td>\n",
       "      <td>Ribs are great, as are the mac and cheese, fri...</td>\n",
       "      <td>[AF1QipNVys4yq-5w_3EsDdHpSc9ZNb7Nl30Mfb6Y0Gup]</td>\n",
       "      <td>[[109802745326785766951_60524fa9f09a4ffff042f9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                business_id                user_id  rating  \\\n",
       "0  60567465d335d0abfb415b26  101074926318992653684       4   \n",
       "1  6050fa9f5b4ccec8d5cae994  117065749986299237881       5   \n",
       "2  604be10877e81aaed3cc9a1e  106700937793048450809       4   \n",
       "3  60411e017cd8bf130362365a  101643045857250355161       5   \n",
       "4  604139dd7cd8bf1303624208  109802745326785766951       4   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  The tang of the tomato sauce is outstanding. A...   \n",
       "1              Chicken and waffles were really good!   \n",
       "2  The appetizer of colossal shrimp was very good...   \n",
       "3  The fish tacos here  omg! The salad was great ...   \n",
       "4  Ribs are great, as are the mac and cheese, fri...   \n",
       "\n",
       "                                                pics  \\\n",
       "0  [AF1QipM-2IRmvitARbcJr7deWfe5hyVBg_ArPMQSYvq0,...   \n",
       "1     [AF1QipMpfxIZUT_aymQ3qPGO-QgGYzxbtLZGmHufAp2s]   \n",
       "2  [AF1QipMNnqM5X9sSyZ9pXRZ1jvrURHN9bZhGdzuEXoP8,...   \n",
       "3  [AF1QipM-a6AGGp4Hgk5RD0gY5sDRp5kEfB1hZLvlRkft,...   \n",
       "4     [AF1QipNVys4yq-5w_3EsDdHpSc9ZNb7Nl30Mfb6Y0Gup]   \n",
       "\n",
       "                                     history_reviews  \n",
       "0  [[101074926318992653684_6056272797d555cc6fb0d1...  \n",
       "1  [[117065749986299237881_605206f8d8c08f462b93e8...  \n",
       "2  [[106700937793048450809_6044300b27f39b7b5d1dbf...  \n",
       "3  [[101643045857250355161_604fbdd099686c10168c91...  \n",
       "4  [[109802745326785766951_60524fa9f09a4ffff042f9...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"filter_all_t.json\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "train_raw = data[\"train\"]\n",
    "test_raw  = data[\"test\"]\n",
    "val_raw   = data[\"val\"]\n",
    "\n",
    "train_df = pd.DataFrame(train_raw)\n",
    "test_df  = pd.DataFrame(test_raw)\n",
    "val_df   = pd.DataFrame(val_raw)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a7cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 87013 entries → 29596 users\n",
      "Saved train.json\n",
      "val: 10860 entries → 3700 users\n",
      "Saved val.json\n",
      "test: 11015 entries → 3700 users\n",
      "Saved test.json\n"
     ]
    }
   ],
   "source": [
    "def extract_num_pics(entry):\n",
    "    pics = entry.get(\"pics\", [])\n",
    "    if isinstance(pics, list):\n",
    "        return len(pics)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def convert_split(entries):\n",
    "    grouped = defaultdict(list)\n",
    "\n",
    "    for r in entries:\n",
    "        uid = r[\"user_id\"]\n",
    "\n",
    "        grouped[uid].append({\n",
    "            \"business_id\": r[\"business_id\"],\n",
    "            \"rating\": r[\"rating\"],\n",
    "            \"review_text\": r[\"review_text\"],\n",
    "            \"num_pics\": extract_num_pics(r),\n",
    "        })\n",
    "\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(\"filter_all_t.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        grouped = convert_split(data[split])\n",
    "\n",
    "        output_file = f\"{split}.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(grouped, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"{split}: {len(data[split])} entries → {len(grouped)} users\")\n",
    "        print(f\"Saved {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15c982eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87013, 5) (10860, 5) (11015, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>num_pics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101074926318992653684</td>\n",
       "      <td>60567465d335d0abfb415b26</td>\n",
       "      <td>4</td>\n",
       "      <td>The tang of the tomato sauce is outstanding. A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101074926318992653684</td>\n",
       "      <td>6056272797d555cc6fb0d147</td>\n",
       "      <td>5</td>\n",
       "      <td>The pizza here is the real deal, perfect in ev...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101074926318992653684</td>\n",
       "      <td>604a65c2c6dc737bce7e5a3d</td>\n",
       "      <td>5</td>\n",
       "      <td>Omg the tomato sauce is everything, in the mea...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101074926318992653684</td>\n",
       "      <td>60433b8d8be5d4454df9cc51</td>\n",
       "      <td>4</td>\n",
       "      <td>First time around last year, we stuck to eggs ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101074926318992653684</td>\n",
       "      <td>6055ebe4f69c7b117806fdaa</td>\n",
       "      <td>3</td>\n",
       "      <td>Food was lukewarm, including fried calamari.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id               business_id  rating  \\\n",
       "0  101074926318992653684  60567465d335d0abfb415b26       4   \n",
       "1  101074926318992653684  6056272797d555cc6fb0d147       5   \n",
       "2  101074926318992653684  604a65c2c6dc737bce7e5a3d       5   \n",
       "3  101074926318992653684  60433b8d8be5d4454df9cc51       4   \n",
       "4  101074926318992653684  6055ebe4f69c7b117806fdaa       3   \n",
       "\n",
       "                                         review_text  num_pics  \n",
       "0  The tang of the tomato sauce is outstanding. A...         4  \n",
       "1  The pizza here is the real deal, perfect in ev...         2  \n",
       "2  Omg the tomato sauce is everything, in the mea...         6  \n",
       "3  First time around last year, we stuck to eggs ...         2  \n",
       "4       Food was lukewarm, including fried calamari.         1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_grouped_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for user, entries in data.items():\n",
    "        for entry in entries:\n",
    "            rows.append({\n",
    "                \"user_id\": user,\n",
    "                \"business_id\": entry[\"business_id\"],\n",
    "                \"rating\": entry[\"rating\"],\n",
    "                \"review_text\": entry[\"review_text\"],\n",
    "                \"num_pics\": entry[\"num_pics\"],\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "train_df = load_grouped_json(\"train.json\")\n",
    "val_df   = load_grouped_json(\"val.json\")\n",
    "test_df  = load_grouped_json(\"test.json\")\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce2dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "full_df[\"review_text\"] = full_df[\"review_text\"].astype(str)\n",
    "full_df[\"num_pics\"] = pd.to_numeric(full_df[\"num_pics\"], errors=\"coerce\").fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfc39704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item text embedding: (30831, 50)\n"
     ]
    }
   ],
   "source": [
    "item_text_corpus = full_df.groupby(\"business_id\")[\"review_text\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "tfidf_item = TfidfVectorizer(stop_words=\"english\", max_features=3000)\n",
    "X_item = tfidf_item.fit_transform(item_text_corpus.values)\n",
    "\n",
    "pca_item = PCA(n_components=50)\n",
    "item_text_emb = pca_item.fit_transform(X_item.toarray())\n",
    "\n",
    "item_text_emb = pd.DataFrame(item_text_emb, index=item_text_corpus.index)\n",
    "print(\"Item text embedding:\", item_text_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fd8a8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User text embedding: (36996, 50)\n"
     ]
    }
   ],
   "source": [
    "user_text_corpus = full_df.groupby(\"user_id\")[\"review_text\"].apply(lambda x: \" \".join(x))\n",
    "\n",
    "tfidf_user = TfidfVectorizer(stop_words=\"english\", max_features=3000)\n",
    "X_user = tfidf_user.fit_transform(user_text_corpus.values)\n",
    "\n",
    "pca_user = PCA(n_components=50)\n",
    "user_text_emb = pca_user.fit_transform(X_user.toarray())\n",
    "\n",
    "user_text_emb = pd.DataFrame(user_text_emb, index=user_text_corpus.index)\n",
    "print(\"User text embedding:\", user_text_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77d056d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item num_pics feature: (30831, 1)\n"
     ]
    }
   ],
   "source": [
    "item_num_pics = full_df.groupby(\"business_id\")[\"num_pics\"].mean()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "item_num_pics_scaled = scaler.fit_transform(item_num_pics.values.reshape(-1, 1))\n",
    "\n",
    "item_num_pics_emb = pd.DataFrame(\n",
    "    item_num_pics_scaled,\n",
    "    index=item_num_pics.index,\n",
    "    columns=[\"num_pics_feature\"]\n",
    ")\n",
    "\n",
    "print(\"Item num_pics feature:\", item_num_pics_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbfb72c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD training done.\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "surprise_data = Dataset.load_from_df(\n",
    "    train_df[[\"user_id\", \"business_id\", \"rating\"]],\n",
    "    reader\n",
    ")\n",
    "trainset = surprise_data.build_full_trainset()\n",
    "\n",
    "svd = SVD(\n",
    "    n_factors=50,\n",
    "    lr_all=0.005,\n",
    "    reg_all=0.02,\n",
    "    n_epochs=30,\n",
    ")\n",
    "svd.fit(trainset)\n",
    "print(\"SVD training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d44ecf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User latent: (29596, 50)\n",
      "Item latent: (27896, 50)\n"
     ]
    }
   ],
   "source": [
    "user_latent = {}\n",
    "for u in trainset.all_users():\n",
    "    uid = trainset.to_raw_uid(u)\n",
    "    user_latent[uid] = svd.pu[u]\n",
    "user_latent = pd.DataFrame(user_latent).T\n",
    "\n",
    "item_latent = {}\n",
    "for i in trainset.all_items():\n",
    "    iid = trainset.to_raw_iid(i)\n",
    "    item_latent[iid] = svd.qi[i]\n",
    "item_latent = pd.DataFrame(item_latent).T\n",
    "\n",
    "print(\"User latent:\", user_latent.shape)\n",
    "print(\"Item latent:\", item_latent.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "851f6b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User hybrid: (36996, 101)\n"
     ]
    }
   ],
   "source": [
    "user_hybrid = pd.concat([user_latent, user_text_emb], axis=1)\n",
    "user_hybrid = user_hybrid.fillna(0)\n",
    "user_hybrid[\"dummy_pic\"] = 0.0\n",
    "print(\"User hybrid:\", user_hybrid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9841cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item hybrid: (30831, 101)\n"
     ]
    }
   ],
   "source": [
    "item_latent = item_latent.add_prefix(\"latent_\")\n",
    "item_text_emb = item_text_emb.add_prefix(\"text_\")\n",
    "item_num_pics_emb = item_num_pics_emb.add_prefix(\"pic_\")\n",
    "item_hybrid = pd.concat([\n",
    "    item_latent,\n",
    "    item_text_emb,\n",
    "    item_num_pics_emb\n",
    "], axis=1)\n",
    "\n",
    "item_hybrid = item_hybrid.fillna(0)\n",
    "\n",
    "print(\"Item hybrid:\", item_hybrid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8db06fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user, item):\n",
    "    if user not in user_hybrid.index:\n",
    "        return None\n",
    "    if item not in item_hybrid.index:\n",
    "        return None\n",
    "\n",
    "    u = user_hybrid.loc[user].values\n",
    "    v = item_hybrid.loc[item].values\n",
    "    return float(np.dot(u, v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce2c238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Validation RMSE: 0.8477666427398878\n",
      "SVD Test RMSE: 0.8268605543821556\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_svd(user, item):\n",
    "    try:\n",
    "        return svd.predict(user, item).est\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def eval_rmse_svd(df):\n",
    "    preds, gts = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        p = predict_rating_svd(row.user_id, row.business_id)\n",
    "        if p is not None:\n",
    "            preds.append(p)\n",
    "            gts.append(row.rating)\n",
    "    if len(preds) == 0:\n",
    "        return None\n",
    "    preds, gts = np.array(preds), np.array(gts)\n",
    "    return np.sqrt(((preds - gts)**2).mean())\n",
    "\n",
    "\n",
    "print(\"SVD Validation RMSE:\", eval_rmse_svd(val_df))\n",
    "print(\"SVD Test RMSE:\", eval_rmse_svd(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d36579dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF Recall@10 (val): 0.0\n",
      "CF NDCG@10 (val): 0.0\n",
      "CF Recall@10 (test): 0.0\n",
      "CF NDCG@10 (test): 0.0\n"
     ]
    }
   ],
   "source": [
    "USER_LATENT_MATRIX = user_latent.values\n",
    "USER_IDS = np.array(user_latent.index)\n",
    "\n",
    "ITEM_LATENT_MATRIX = item_latent.values\n",
    "ITEM_IDS = np.array(item_latent.index)\n",
    "\n",
    "# user -> seen items (from train)\n",
    "user_seen_items = (\n",
    "    train_df.groupby(\"user_id\")[\"business_id\"].apply(set).to_dict()\n",
    ")\n",
    "\n",
    "def recommend_topk_cf(user_id, k=10, filter_seen=False):\n",
    "    if user_id not in user_latent.index:\n",
    "        return []\n",
    "\n",
    "    u = user_latent.loc[user_id].values       # shape (d,)\n",
    "    scores = ITEM_LATENT_MATRIX @ u\n",
    "\n",
    "    if filter_seen:\n",
    "        seen = user_seen_items.get(user_id, set())\n",
    "        mask = ~np.isin(ITEM_IDS, list(seen))\n",
    "        scores = scores[mask]\n",
    "        items  = ITEM_IDS[mask]\n",
    "    else:\n",
    "        items = ITEM_IDS\n",
    "\n",
    "    # 选出 top-k\n",
    "    if len(scores) <= k:\n",
    "        top_idx = np.argsort(-scores)\n",
    "    else:\n",
    "        top_idx = np.argpartition(-scores, k)[:k]\n",
    "\n",
    "    top_items = [(items[i], scores[i]) for i in top_idx]\n",
    "    top_items.sort(key=lambda x: x[1], reverse=True)\n",
    "    return top_items\n",
    "\n",
    "def recall_at_k_cf(df, k=10):\n",
    "    recalls = []\n",
    "\n",
    "    for user in df.user_id.unique():\n",
    "        true_items = set(df[df.user_id == user].business_id)\n",
    "\n",
    "        recs = recommend_topk_cf(user, k, filter_seen=False)\n",
    "        rec_items = {i for i, _ in recs}\n",
    "\n",
    "        if not true_items:\n",
    "            continue\n",
    "\n",
    "        recall = len(rec_items & true_items) / len(true_items)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    return np.mean(recalls) if recalls else None\n",
    "\n",
    "\n",
    "def ndcg_at_k_cf(df, k=10):\n",
    "    ndcgs = []\n",
    "\n",
    "    for user in df.user_id.unique():\n",
    "        true_items = set(df[df.user_id == user].business_id)\n",
    "        recs = recommend_topk_cf(user, k, filter_seen=False)\n",
    "        rec_items = [i for i, _ in recs]\n",
    "\n",
    "        if not true_items:\n",
    "            continue\n",
    "\n",
    "        dcg = 0.0\n",
    "        for idx, item in enumerate(rec_items):\n",
    "            if item in true_items:\n",
    "                dcg += 1 / np.log2(idx + 2)\n",
    "\n",
    "        idcg = 1.0\n",
    "        ndcgs.append(dcg / idcg)\n",
    "\n",
    "    return np.mean(ndcgs) if ndcgs else None\n",
    "\n",
    "print(\"CF Recall@10 (val):\", recall_at_k_cf(val_df, 10))\n",
    "print(\"CF NDCG@10 (val):\", ndcg_at_k_cf(val_df, 10))\n",
    "print(\"CF Recall@10 (test):\", recall_at_k_cf(test_df, 10))\n",
    "print(\"CF NDCG@10 (test):\", ndcg_at_k_cf(test_df, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b6d7feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train items: 27896\n",
      "Total val items: 7835\n",
      "Total test items: 7880\n",
      "Val unseen rate: 0.19821314613911933\n",
      "Test unseen rate: 0.19771573604060913\n",
      "Train interactions per user:\n",
      " count    29596.000000\n",
      "mean         2.940026\n",
      "std          2.071721\n",
      "min          2.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max         46.000000\n",
      "dtype: float64\n",
      "Val interactions per user:\n",
      " count    3700.000000\n",
      "mean        2.935135\n",
      "std         1.910998\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max        22.000000\n",
      "dtype: float64\n",
      "Test interactions per user:\n",
      " count    3700.000000\n",
      "mean        2.977027\n",
      "std         2.057635\n",
      "min         2.000000\n",
      "25%         2.000000\n",
      "50%         2.000000\n",
      "75%         3.000000\n",
      "max        31.000000\n",
      "dtype: float64\n",
      "2     2257\n",
      "3      690\n",
      "4      311\n",
      "5      177\n",
      "6       84\n",
      "7       60\n",
      "8       27\n",
      "9       30\n",
      "10      15\n",
      "11       8\n",
      "12       9\n",
      "13       6\n",
      "14       3\n",
      "15      10\n",
      "16       1\n",
      "17       1\n",
      "18       1\n",
      "19       3\n",
      "20       1\n",
      "21       1\n",
      "22       2\n",
      "25       1\n",
      "27       1\n",
      "31       1\n",
      "Name: count, dtype: int64\n",
      "count    27896.000000\n",
      "mean         3.119193\n",
      "std          5.182107\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max        210.000000\n",
      "dtype: float64\n",
      "Items with only 1 interaction: 12606\n",
      "Items with only ≤2 interactions: 18303\n",
      "Total items: 27896\n",
      "Train/Val item overlap: 0.8017868538608807\n",
      "Train/Test item overlap: 0.8022842639593909\n",
      "Test items without latent vector: 1558\n",
      "Rate: 0.19771573604060913\n",
      "Train items: set()\n",
      "Test items: {'604ba46f20f26f37fb9d7d69', '604bf6a75041fa50c4bce594', '6055eda33019cb0a47838b25'}\n",
      "Overlap: set()\n",
      "count    36996.000000\n",
      "mean         2.943237\n",
      "std          2.054776\n",
      "min          2.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max         46.000000\n",
      "Name: business_id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_items = set(train_df.business_id)\n",
    "val_items = set(val_df.business_id)\n",
    "test_items = set(test_df.business_id)\n",
    "\n",
    "val_unseen = val_items - train_items\n",
    "test_unseen = test_items - train_items\n",
    "\n",
    "print(\"Total train items:\", len(train_items))\n",
    "print(\"Total val items:\", len(val_items))\n",
    "print(\"Total test items:\", len(test_items))\n",
    "\n",
    "print(\"Val unseen rate:\", len(val_unseen) / len(val_items))\n",
    "print(\"Test unseen rate:\", len(test_unseen) / len(test_items))\n",
    "\n",
    "train_user_counts = train_df.groupby(\"user_id\").size()\n",
    "val_user_counts   = val_df.groupby(\"user_id\").size()\n",
    "test_user_counts  = test_df.groupby(\"user_id\").size()\n",
    "\n",
    "print(\"Train interactions per user:\\n\", train_user_counts.describe())\n",
    "print(\"Val interactions per user:\\n\",   val_user_counts.describe())\n",
    "print(\"Test interactions per user:\\n\",  test_user_counts.describe())\n",
    "\n",
    "test_per_user = test_df.groupby(\"user_id\").size()\n",
    "print(test_per_user.value_counts().sort_index())\n",
    "\n",
    "item_popularity = train_df.groupby(\"business_id\").size()\n",
    "print(item_popularity.describe())\n",
    "\n",
    "print(\"Items with only 1 interaction:\", (item_popularity == 1).sum())\n",
    "print(\"Items with only ≤2 interactions:\", (item_popularity <= 2).sum())\n",
    "print(\"Total items:\", len(item_popularity))\n",
    "\n",
    "print(\"Train/Val item overlap:\", len(train_items & val_items) / len(val_items))\n",
    "print(\"Train/Test item overlap:\", len(train_items & test_items) / len(test_items))\n",
    "\n",
    "missing_latent_items = [iid for iid in test_items if iid not in item_latent.index]\n",
    "print(\"Test items without latent vector:\", len(missing_latent_items))\n",
    "print(\"Rate:\", len(missing_latent_items) / len(test_items))\n",
    "\n",
    "sample_user = test_df.user_id.iloc[0]\n",
    "u_train_items = set(train_df[train_df.user_id==sample_user].business_id)\n",
    "u_test_items  = set(test_df[test_df.user_id==sample_user].business_id)\n",
    "\n",
    "print(\"Train items:\", u_train_items)\n",
    "print(\"Test items:\", u_test_items)\n",
    "print(\"Overlap:\", u_train_items & u_test_items)\n",
    "\n",
    "unique_per_user = full_df.groupby(\"user_id\").business_id.nunique()\n",
    "print(unique_per_user.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b27b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
